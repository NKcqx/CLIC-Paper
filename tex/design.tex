\section{SYSTEM DESIGN}

\subsection{Architecture}
% 微服务

\begin{figure}[tbh]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/CLIC-arch-2.pdf}
    \caption{The architecture of CLIC}
    \label{fig:architecture}
  \end{figure}
% The proxy program accepts the job submit and parse it to domain-specific-language (DSL). 
% The driver program submits the DSL written job to the physical platform like Spark cluster, Tensorflow cluster, etc.

\textbf{Cloud-Native Task Deployment} Besides designing the cloud-native framework, CLIC decouples data processing platforms from the framework to facilitate extensible platform integration and independent deployment.
All physical operators of a platform are built in an image, thus each platform is developed and maintained independently.
To execute physical operators in one job, a platform image contains a proxy and a driver program.
The proxy program accepts the job submit and parse it to domain-specific-language (DSL). 
The driver program submits the DSL written job to the physical platform like Spark cluster, Tensorflow cluster, etc.


Moreover, one platform of different versions are kept as separate images to provide backward compatibility.

To mitigate expensive data transfer between operators, the input and output of an operator is an abstraction of the platform (e.g., RDD or numpy.array) or a specific data structure (int [] in C).
In this way, when adjacent tasks belong to the same platform, they can be merged and deployed as one job.
Instead, tasks of different platforms are launched as separate jobs and passes data through a file system.
After platform selection, each task in a workflow is assigned with an image of its corresponding platform.

To execute physical operators in one job, a platform image contains a driver program to drive the workflow execution. 
In the deployment of a job, Executor passes the operators information of the job to the driver program in the platform image. 
The driver program calls the specified data source operator to read data from the file system and transfers into the input abstraction and formats of operators, such as building an RDD. Then driver program interprets the workflow, calls the corresponding operators and passes data one by one. In the end, the driver program calls the data sink operator to serialize data and write to specified directory in the file system.
Overall, CLIC merges and deploys operators of the same platform as one task while automatically connecting adjacent platforms with automatic data transformation. 


% As shown in the figure, the CLIC server consists of a publish/subscribe mode event bus. 
% All the microservices interact with each other by publishing and subscribing to a specific channel in the event bus.

\subsection{Programming Interface}
% Different computing paradigms require different data models.
% In order to support multiple paradigms, CLIC offers various data models, e.g. Table, Dictionary, Matrix/Vector and Graph.
% For a hybrid workflow that contains multiple paradigms, CLIC provides a set of model conversion operations to link two paradigms.

\subsection{Physical Operator}
mapping, management.

\subsection{Platform Selection}
%  CLIC first encodes the operators to vectors and then utilizes the Graph Convolutional Network(GCN) to solve this problem.
% 说到 there exists a best one，CLIC 会根据factor（可以直接说哪些factor） 自动选出最好的，就行了
% 其余的放在 sec.5 讲

% Each logical operator in the workflow need to be first transformed to a specific physical operator for execution.
% Although, a logical operator can have multiple available physical operators, there exists a best one, transforming to which can lead to the best overall performance. 

% 每个opt都要映射为physical 才行 。
% 有一个是best
% 找best需要取决于数据量、计算任务、硬件。

% For the flexibility of expanding the fast growing platforms, the GCN model is made adaptive to new platforms without retraining the model.
% Moreover, the model is designed as hardware-conscious to cope with the computing resource variations.

% To automatically select the best physical operator,
% CLIC first encodes the operators to vectors and then utilizes the Graph Convolutional Network(GCN) to solve this problem.



\subsection{Case Study}
We adopt sentiment classification as a case to demonstrate how CLIC works. It is a common nature language processing task that classifies documents based on the semantics. The data processing tasks mainly include data ETL (Extract, Transforming, Loading) and training of a classification model. The pseudo-code of a simple implementation is shown in Listing \ref{code:workflow}.

\begin{listing}[ht]
\begin{minted}[frame=lines,
framesep=2mm,
baselinestretch=1.2,
fontsize=\footnotesize,
linenos]{python}
source1 = read('BBC-News.txt’)
source2 = read('Hamlet.txt')
corpus = join(clean_source1, clean_source2)

word_embedding = toMatrix(clean_corpus, Word2Vec)
    
model = Model('LSTM')
train(model, word_embedding['train'])
topic = test(model, word_embedding['test'])
\end{minted}
\caption{Pseudo-code of sentiment classification in CLIC}
\label{code:workflow}
\end{listing}
The processing steps are as follows. 1) Based on logical operators, PlanBuilder builds the logical plan for the workflow. As shown in Figure \ref{fig:dag1}, the logical plan is a  DAG consists of five logical operators. 2) Optimizer applies optimizations on the logical plan. In this case, because the data volume of \textit{source2} is way lesser than source1, CLIC implicitly inserts a \textit{broadcast} operator to put \textit{source2}’s data on all nodes in order to reduce communication times. The optimized logical plan is shown in Figure \ref{fig:dag2}. 3) Logical operators are assigned to platforms with a GCN model. Figure \ref{fig:dag3} shows the potential platforms of each logical operator and marks the selected platforms with red triangles. Two platforms are selected in this case, where model training is placed on Pytorch while the rest operators are assigned to Spark. 4) The adjacent Spark operators and the PyTorch operator are grouped into two tasks as shown in Figure \ref{fig:dag4}, because merging adjacent operators of the same platform as one task can mitigate data transfer overheads. Then Scheduler chooses the corresponding container images for the two tasks and deploys them on the cloud subsequently. Note that, in the generation of the physical plan, PlanBuilder implicitly inserts a \textit{sink} operator in Spark to output the intermediate results and a \textit{source} operator in Pytorch to read Spark’s results.
